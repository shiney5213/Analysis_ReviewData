{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flowchart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'crawler_flowchart.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T07:48:29.432737Z",
     "start_time": "2020-04-08T07:48:28.748473Z"
    }
   },
   "outputs": [],
   "source": [
    "# import mysql.connector\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "#from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import numpy as np\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. crawrler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T07:48:45.802483Z",
     "start_time": "2020-04-08T07:48:30.376474Z"
    }
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "driver.get(\"http://www.google.com\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "element = driver.find_element_by_name('q')\n",
    "\n",
    "element.clear()\n",
    "element.send_keys('google map')\n",
    "element.submit()\n",
    "\n",
    "element = driver.find_element_by_xpath('//h3[@class=\"LC20lb DKV0Md\"]')\n",
    "element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T07:58:17.144097Z",
     "start_time": "2020-04-08T07:58:17.129097Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_info(html, shop_name, shop_address):\n",
    "# shop 주소, 총 별점 갖고오기\n",
    "    search_name, address, total_score, match=get_totalScore(html,shop_name, shop_address)\n",
    "    \n",
    "    # shop info가 있는가(addrsss로 확인)\n",
    "    if address == '':\n",
    "        review_list = ''\n",
    "        score_list = ''\n",
    "        return search_name, address,total_score, review_list, score_list, match \n",
    "\n",
    "    # 리뷰가 없는 경우    \n",
    "    if  total_score == 0:\n",
    "        review_list = 0\n",
    "        score_list= 0\n",
    "        \n",
    "    # 리뷰가 있는 경우\n",
    "    else:\n",
    "        # 리뷰 text(버튼 )클릭\n",
    "        review_button = driver.find_element_by_xpath('//button[@class=\"jqnFjrOWMVU__button gm2-caption\"]')\n",
    "        review_button.click()\n",
    "\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # 스크롤 다운\n",
    "        try:\n",
    "            element = driver.find_element_by_xpath('//span[@class=\"section-review-text\"]')\n",
    "            element.click()\n",
    "\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "\n",
    "        i = 0\n",
    "        while  True:\n",
    "            i += 1\n",
    "            html = driver.find_element_by_tag_name('html')\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "            text1 = html.text\n",
    "            html.send_keys(Keys.END)\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "            html = driver.find_element_by_tag_name('html')\n",
    "            text2 = html.text\n",
    "\n",
    "            if text1 == text2:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "        review_html = driver.page_source\n",
    "\n",
    "        review_list, score_list=get_review(review_html) \n",
    "        driver.back()\n",
    "\n",
    "    return search_name, address, total_score, review_list, score_list, match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T07:58:17.350097Z",
     "start_time": "2020-04-08T07:58:17.341096Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_review(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # 개별 리뷰\n",
    "    total_review =soup.find_all('span',attrs = {'class': \"section-review-text\"} )\n",
    "\n",
    "    review_list=[]\n",
    "    for i, review in enumerate(total_review):\n",
    "        review_list.append(review.text)\n",
    "\n",
    "    #### 개별 별점\n",
    "    scores =soup.find_all('span',attrs = {'class': \"section-review-stars\", 'role': 'img'} )\n",
    "\n",
    "    score_list = []\n",
    "    for score in scores:\n",
    "        score_list.append(score.attrs['aria-label'])\n",
    "\n",
    "    return review_list, score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:34.444848Z",
     "start_time": "2020-04-08T08:00:34.429847Z"
    }
   },
   "outputs": [],
   "source": [
    "def start_crwarling(k, forpet_hash,shop_name, shop_address):\n",
    "    print(k, shop_name, shop_address)\n",
    "\n",
    "    # shop 이름 입력\n",
    "    try:\n",
    "        element = driver.find_element_by_xpath('//input[@autofocus=\"autofocus\"]')\n",
    "        element.clear()\n",
    "    \n",
    "    except:\n",
    "        element = driver.find_element_by_xpath('//h3[@class=\"LC20lb DKV0Md\"]')\n",
    "        element.click()\n",
    "        \n",
    "    search_word = shop_name + ' ' +shop_address[0]\n",
    "#     search_word = shop_name\n",
    "    element.send_keys(search_word)\n",
    "    element.submit()\n",
    "    time.sleep(1)\n",
    "        \n",
    "    search_button = driver.find_element_by_xpath('//button[@class=\"searchbox-searchbutton\"]')\n",
    "    search_button.click()\n",
    "    \n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # 키워드 입력 후, dict로 인덱스와 match 여부 받아오기\n",
    "    select_shop_html = driver.page_source\n",
    "    shop_select_dict= find_shop_by_name(select_shop_html, shop_name)\n",
    "    \n",
    "    # shoh이 여러개인 경우\n",
    "    if len(shop_select_dict) != 0:\n",
    "        print(f'shop이 {len(shop_select_dict)}개입니다')\n",
    "        for index, name in shop_select_dict.items():\n",
    "            shop_index =  2 * int(index) -1\n",
    "            \n",
    "            search_name = name\n",
    "#             \n",
    "            time.sleep(3)\n",
    "\n",
    "            try:\n",
    "                select_shop = driver.find_element_by_xpath(f'//div[@class = \"section-layout section-scrollbox scrollable-y scrollable-show section-layout-flex-vertical\"]/div/div[{shop_index}]/div[1]/div[1]')\n",
    "\n",
    "                select_shop.click()\n",
    "\n",
    "                time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "                html = driver.page_source\n",
    "\n",
    "                search_name, address, total_score, review_list, score_list, match =get_info(html, shop_name, shop_address)\n",
    "                print(f'{index}번째 shop:', search_name, address, total_score, match )\n",
    "            except:\n",
    "                search_name = shop_name\n",
    "                address = ''\n",
    "                total_score = ''\n",
    "                match = 'not info'\n",
    "                address = ''\n",
    "                review_list = ''\n",
    "                score_list = ''\n",
    "           \n",
    "            save_dataframe(forpet_hash, search_name, shop_address, address, total_score, review_list, score_list, match)\n",
    "        \n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            driver.back()  \n",
    "     \n",
    "    # shop이 1개 인경우\n",
    "    else:\n",
    "        print('shop이 1개입니다')\n",
    "        html = driver.page_source\n",
    "        search_name, address, total_score, review_list, score_list, match =get_info(html, shop_name, shop_address)\n",
    "        print(f'shop 1개, {search_name}, {address}, {match} ')\n",
    "        \n",
    "        save_dataframe(forpet_hash, search_name, shop_address, address, total_score, review_list, score_list, match)\n",
    "    driver.back()  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:34.705850Z",
     "start_time": "2020-04-08T08:00:34.692892Z"
    }
   },
   "outputs": [],
   "source": [
    "# 여러개의  shop 목록에서 주소로 찾기\n",
    "def find_shop_by_name(select_shop_html, shop_name):\n",
    "    soup = BeautifulSoup(select_shop_html, 'html.parser')\n",
    "#     print(select_shop_html)\n",
    "    all_shop_name = soup.find_all('div', attrs = {'class': \"section-result-title-container\"} )\n",
    "    \n",
    "    shop_select_dict = {}\n",
    "    for i, shop in enumerate(all_shop_name):\n",
    "        include_word = ['동물', '펫', '애견', 'dot','cat','도그','캣','pet','야옹','멍멍', '독', '멍','퍼피']\n",
    "        name_include_word = sum([ word in shop.text  for word in include_word]) \n",
    "        \n",
    "        # 이름이 같은 경우\n",
    "        if shop_name == shop.text :\n",
    "            shop_select_dict[str(i+1)] = [shop.text, 'same_name']  \n",
    "        # 이름이 비슷한 경우\n",
    "        elif name_include_word >= 1:\n",
    "            shop_select_dict[str(i+1)] = [shop.text,'simiral_name']\n",
    "        else:\n",
    "            pass\n",
    "#     print(shop_select_dict)\n",
    "    return shop_select_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:34.931857Z",
     "start_time": "2020-04-08T08:00:34.916844Z"
    }
   },
   "outputs": [],
   "source": [
    "# 주소와 total 별점 가져오기\n",
    "def get_totalScore(html,shop_name, shop_address):\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    infos =soup.find_all('span',attrs = {'class': \"section-info-text\"} )\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    \n",
    "    # 검색 결과가 있는 경우\n",
    "    try: \n",
    "        search_name = soup.find_all('div', attrs = {'class':'section-hero-header-title-description' })[0].text.replace(' ','')\n",
    "        if shop_name in search_name:\n",
    "            search_name = shop_name\n",
    "        else:\n",
    "            p = re.compile(\"[가-힣]\")\n",
    "            search_name = ''.join(p.findall(search_name)).replace('주','')\n",
    "        \n",
    "        print('serach_name', search_name, 'shop_name', shop_name)\n",
    "        \n",
    "        #  shop이름이 일치하는 경우\n",
    "        if shop_name in search_name:\n",
    "            # shop 정보가 없는 경우\n",
    "            if len(infos)== 0:\n",
    "                total_score = ''\n",
    "                match = 'not info'\n",
    "                address = ''\n",
    "\n",
    "                return address, total_score\n",
    "            # shop 정보가 있는 경우    \n",
    "            else:\n",
    "                address =infos[0].text\n",
    "\n",
    "                gu = shop_address[0] in address\n",
    "                dong = shop_address[1] in address\n",
    "                bungi = shop_address[2] in address\n",
    "\n",
    "\n",
    "                if (gu and dong and bungi) or (dong and bungi):\n",
    "                    match = 'match_all'\n",
    "                elif (gu and dong) or dong:\n",
    "                    match = 'match_dong'\n",
    "                elif gu:\n",
    "                    match = 'match_gu'\n",
    "                else:\n",
    "                    match = 'not_match' \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        #shop이름이 다른 경우\n",
    "        else:\n",
    "            address =infos[0].text\n",
    "            match = 'x'\n",
    "\n",
    "\n",
    "        total_score = soup.find_all('div',attrs = {'class': \"gm2-display-2\"} )\n",
    "\n",
    "        if len(total_score)!=0:\n",
    "            total_score = total_score[0].text\n",
    "        else:\n",
    "            total_score = 0\n",
    "    \n",
    "    # 검색 결과가 없는 경우\n",
    "    except:\n",
    "        total_score = ''\n",
    "        match = 'not info'\n",
    "        address = ''\n",
    "        search_name = shop_name\n",
    "    \n",
    "    return search_name, address, total_score, match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:35.113857Z",
     "start_time": "2020-04-08T08:00:35.101846Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_dataframe(forpet_hash, search_name, shop_address, address, total_score, review_list, score_list, match):\n",
    "    \n",
    "    # shop 정보가 없는 경우\n",
    "    if address == '':\n",
    "        not_info_table_insert(not_info_table, forpet_hash, search_name, match)\n",
    "    \n",
    "    # shop 정보가 있는 경우\n",
    "    else:\n",
    "        # match 여부에 따라\n",
    "        if match == 'match_all':\n",
    "            table_total = match_total_table\n",
    "            table_review = match_review_table\n",
    "\n",
    "        elif match == 'x':\n",
    "            table_total = x_total_table\n",
    "            table_review = x_review_table\n",
    "\n",
    "        # shop 이름만 같은 경우, match = match_dong, match_gu, not_match\n",
    "        else:    \n",
    "            table_total = not_match_total_table\n",
    "            table_review = not_match_review_table\n",
    "\n",
    "        total_table_insert(table_total, forpet_hash, search_name, shop_address, address, total_score, review_list, match)\n",
    "        review_table_insert(table_review, forpet_hash, search_name, shop_address, address, review_list, score_list, match)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. table\n",
    "#### 1. total table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:35.520893Z",
     "start_time": "2020-04-08T08:00:35.499845Z"
    }
   },
   "outputs": [],
   "source": [
    "match_total_table = pd.read_csv('data/match_total_table.csv', index_col =  0)\n",
    "not_match_total_table = pd.read_csv('data/not_match_total_table.csv', index_col = 0)\n",
    "x_total_table = pd.read_csv('data/x_total_table.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:35.694546Z",
     "start_time": "2020-04-08T08:00:35.684545Z"
    }
   },
   "outputs": [],
   "source": [
    "def total_table_insert(total_table, forpet_hash, search_name, shop_address, address, total_score, review_list, match):\n",
    "    if len(total_table[total_table['address']== address]) == 0:\n",
    "        # shop 정보가 없고, total_sclre가 없는 경우\n",
    "        if total_score == '':\n",
    "            total_table.loc[len(total_table)+1] = [forpet_hash, search_name, shop_address,  address, np.nan, np.nan, match]\n",
    "        # shop 정보가 있고, total_score가 있는 경우\n",
    "        elif total_score == 0:\n",
    "            total_table.loc[len(total_table)+1] = [forpet_hash, search_name, shop_address, address, 0, 0, match]\n",
    "\n",
    "        #total score이 없는 경우\n",
    "        else:\n",
    "            total_table.loc[len(total_table)+1] = [forpet_hash, search_name, shop_address, address,total_score, len(review_list), match]\n",
    "        print(f'total_table: {search_name}, {address} 등록완료')\n",
    "    else:\n",
    "        print(f'total_table: {search_name}, {address} 이미 있음')\n",
    "    return total_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T09:58:53.111871Z",
     "start_time": "2020-03-10T09:58:53.107873Z"
    }
   },
   "source": [
    "#### 2. review table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:36.081548Z",
     "start_time": "2020-04-08T08:00:36.061549Z"
    }
   },
   "outputs": [],
   "source": [
    "not_match_review_table= pd.read_csv('./data/not_match_review_table.csv', index_col = 0)\n",
    "match_review_table = pd.read_csv('./data/match_review_table.csv', index_col = 0)\n",
    "x_review_table = pd.read_csv('./data/x_review_table.csv', index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:36.250551Z",
     "start_time": "2020-04-08T08:00:36.236549Z"
    }
   },
   "outputs": [],
   "source": [
    "def review_table_insert(review_table, forpet_hash, search_name, shop_address, address, review_list, score_list, match):\n",
    "    if len(review_table[review_table['address']== address]) == 0:\n",
    "        # shop 정보가 없고, total_sclre가 없는 경우\n",
    "        if review_list == '':\n",
    "            review_table.loc[len(review_table)+1] = [forpet_hash, search_name, shop_address, address, 1,  np.nan, np.nan, match]\n",
    "            print(f'review_table: {search_name}, {address} 등록완료')\n",
    "\n",
    "        # shop 정보가 있고, total_score가 있는 경우\n",
    "        elif review_list == 0:\n",
    "            review_table.loc[len(review_table)+1] = [forpet_hash, search_name, shop_address, address, 1, 0, 0, match]\n",
    "            print(f'review_table: {search_name}, {address} 등록완료')\n",
    "\n",
    "        #total score이 없는 경우\n",
    "        else:\n",
    "            for i, (review, score, match) in enumerate(zip(review_list, score_list, match)):\n",
    "                review_table.loc[i+1+len(review_table)] = [forpet_hash, search_name, shop_address, address, i, review, score, match]\n",
    "            print(f'review_table: {search_name}, {address}, {len(review_list)} 등록완료')\n",
    "    else:\n",
    "        print(f'review_table: {search_name}, {address} 이미 있음')\n",
    "\n",
    "    return review_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.not_info_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:36.630547Z",
     "start_time": "2020-04-08T08:00:36.616546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_info_table = pd.read_csv('./data/not_info_table.csv', index_col = 0)\n",
    "len(not_info_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:36.811551Z",
     "start_time": "2020-04-08T08:00:36.805549Z"
    }
   },
   "outputs": [],
   "source": [
    "def not_info_table_insert(not_info_table, forpet_hash, shop_name, match):\n",
    "    not_info_table.loc[1+len(not_info_table)] = [forpet_hash, shop_name, match]\n",
    "    print(f'not_info_table: {shop_name} 등록완료')\n",
    "    return not_info_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ordinary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:37.237111Z",
     "start_time": "2020-04-08T08:00:37.181118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forpet_hash</th>\n",
       "      <th>address_name</th>\n",
       "      <th>place_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b793eb834462b029e435eaeb49433efc61755c9e15a24...</td>\n",
       "      <td>서울 종로구 평창동 530-8</td>\n",
       "      <td>쿠나이앤티</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f5169c15a126e4059f0a89bb80fccd236693d5056d24ae...</td>\n",
       "      <td>서울 종로구 창신동 468-1</td>\n",
       "      <td>애견용품할인매장</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa26d23f20a9b5642a6689f2a2761ca470703ebbd514eb...</td>\n",
       "      <td>서울 종로구 창신동 436-64</td>\n",
       "      <td>펫클럽 청계점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2806f173e3a783ed14d74c9a83da2f62c34f45d470e893...</td>\n",
       "      <td>서울 종로구 홍지동 103-24</td>\n",
       "      <td>나니스펫푸드</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa18fd6e2328f00ac2567b7a37a4db308ceee03a01924c...</td>\n",
       "      <td>서울 종로구 필운동 137-5</td>\n",
       "      <td>서촌양품</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         forpet_hash       address_name  \\\n",
       "0  4b793eb834462b029e435eaeb49433efc61755c9e15a24...   서울 종로구 평창동 530-8   \n",
       "1  f5169c15a126e4059f0a89bb80fccd236693d5056d24ae...   서울 종로구 창신동 468-1   \n",
       "2  aa26d23f20a9b5642a6689f2a2761ca470703ebbd514eb...  서울 종로구 창신동 436-64   \n",
       "3  2806f173e3a783ed14d74c9a83da2f62c34f45d470e893...  서울 종로구 홍지동 103-24   \n",
       "4  aa18fd6e2328f00ac2567b7a37a4db308ceee03a01924c...   서울 종로구 필운동 137-5   \n",
       "\n",
       "  place_name  \n",
       "0      쿠나이앤티  \n",
       "1   애견용품할인매장  \n",
       "2    펫클럽 청계점  \n",
       "3     나니스펫푸드  \n",
       "4       서촌양품  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinary_table = pd.read_csv('data/mysql_forpet_shop.csv', index_col = 0)\n",
    "ordinary_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:37.346120Z",
     "start_time": "2020-04-08T08:00:37.340111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8582"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ordinary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:46.820674Z",
     "start_time": "2020-04-08T08:00:37.520113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266 퍼피홀릭 ['제주시', '아라이동', '3003-10']\n",
      "shop이 1개입니다\n",
      "serach_name 퍼피홀릭 shop_name 퍼피홀릭\n",
      "shop 1개, 퍼피홀릭, 제주특별자치도 제주시 아라이동, match_dong \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-594542b39d11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mshop_address\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0maddress_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mshop_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplace_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mstart_crwarling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforpet_hash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshop_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-277350e13771>\u001b[0m in \u001b[0;36mstart_crwarling\u001b[1;34m(k, forpet_hash, shop_name, shop_address)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'shop 1개, {search_name}, {address}, {match} '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0msave_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforpet_hash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshop_address\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreview_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-af77376d95fe>\u001b[0m in \u001b[0;36msave_dataframe\u001b[1;34m(forpet_hash, search_name, shop_address, address, total_score, review_list, score_list, match)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mtable_review\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnot_match_review_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mtotal_table_insert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable_total\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforpet_hash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshop_address\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreview_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mreview_table_insert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable_review\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforpet_hash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshop_address\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreview_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-8ef4fc0051a0>\u001b[0m in \u001b[0;36mtotal_table_insert\u001b[1;34m(total_table, forpet_hash, search_name, shop_address, address, total_score, review_list, match)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m# shop 정보가 있고, total_score가 있는 경우\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtotal_score\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mtotal_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mforpet_hash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshop_address\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m#total score이 없는 경우\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\crawling\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\crawling\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m         \u001b[1;31m# set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\documents\\workspace\\crawling\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1116\u001b[0m                     \u001b[1;31m# must have conforming columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1118\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot set a row with mismatched columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "SCROLL_PAUSE_TIME = 2\n",
    "start_row = 2266\n",
    "for k in range(start_row, len(ordinary_table)):\n",
    "    forpet_hash, address_name, place_name= ordinary_table.loc[k] \n",
    "  \n",
    "    shop_address =address_name.split(' ')[1:]\n",
    "    shop_name = place_name.replace(' ','')\n",
    "    start_crwarling(k, forpet_hash, shop_name, shop_address)\n",
    "    \n",
    "    print('\\n')\n",
    "    try:\n",
    "        back_button = driver.find_element_by_xpath('//button[@class=\"ozj7Vb3wnYq__action-button-clickable\"]')\n",
    "        back_button.click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    if k % 100 == 0:\n",
    "        match_total_table.to_csv('match_total_table.csv')\n",
    "        not_match_total_table.to_csv('not_match_total_table.csv')\n",
    "        match_review_table.to_csv('match_review_table.csv')\n",
    "        not_match_review_table.to_csv('not_match_review_table.csv')\n",
    "        x_total_table.to_csv('x_total_table.csv')\n",
    "        x_review_table.to_csv('x_review_table.csv')\n",
    "        not_info_table.to_csv('not_info_table.csv')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T08:00:46.824673Z",
     "start_time": "2020-04-08T08:00:37.683Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print('match_total_table\\n',match_total_table)\n",
    "print('not_match_total_table\\n',not_match_total_table)\n",
    "print('match_review_table\\n',match_review_table)\n",
    "print('not_match_review_table\\n',not_match_review_table)\n",
    "print('x_total_table\\n', x_total_table)\n",
    "print('x_review_table\\n', x_review_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "167.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
